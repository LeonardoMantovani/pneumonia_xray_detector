{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a0ba45",
   "metadata": {},
   "source": [
    "# Final Notebook\n",
    "\n",
    "This notebook contains the code of our project, aimed at extend the original's one by implementing active learning in it and demonstratig its benefits.\n",
    "\n",
    "More information about this work in the Project Report attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b516250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: add imports\n",
    "import numpy as np\n",
    "import os\n",
    "import skimage\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42650f92",
   "metadata": {},
   "source": [
    "### Constants & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdfed42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible labels present in the dataset\n",
    "# (NOTE: labeled datasets are expected to be folders with one subfolder per label, and inside each subfolder all the images of that type)\n",
    "POSSIBLE_LABELS = ['PNEUMONIA', 'NORMAL']\n",
    "\n",
    "# The size dataset images will be resized to before feature extraction\n",
    "IMG_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c0889",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f74fd891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract features from a given image\n",
    "# using scikit-image Histogram of Oriented Gradient features extractor\n",
    "def extract_hog_features(image):\n",
    "    resized_image = skimage.transform.resize(\n",
    "        image,\n",
    "        (IMG_SIZE, IMG_SIZE),\n",
    "        anti_aliasing=True,\n",
    "        preserve_range=True\n",
    "    ).astype(np.uint8)\n",
    "\n",
    "    features = skimage.feature.hog(\n",
    "        resized_image,\n",
    "        orientations=9,\n",
    "        pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(2, 2),\n",
    "        block_norm='L2-Hys',\n",
    "        transform_sqrt=False,\n",
    "        feature_vector=True\n",
    "    )\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a48a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads images from the given directory and returns their extracted features and labels as numpy arrays\n",
    "def load_dataset(data_path):\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # for each folder of the dataset (each folder corresponds to a different class of labeled data)...\n",
    "    for label in POSSIBLE_LABELS:\n",
    "        class_path = os.path.join(data_path, label)\n",
    "        class_label = POSSIBLE_LABELS.index(label)\n",
    "\n",
    "        # for each image in the folder...\n",
    "        for img_name in os.listdir(class_path):\n",
    "            try:\n",
    "                # load the image as an array of float values of its pixels (in graycale since it's x-ray)\n",
    "                img = skimage.io.imread(\n",
    "                    os.path.join(class_path, img_name),\n",
    "                    as_gray=True\n",
    "                )\n",
    "\n",
    "                # extract the hog features from the resized image using the method defined above\n",
    "                hog_features = extract_hog_features(img)\n",
    "\n",
    "                # store the extracted features in the features list and the index of the current class as their respective label\n",
    "                features_list.append(hog_features)\n",
    "                labels_list.append(class_label)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_name}: {e}\")\n",
    "    \n",
    "    return np.array(features_list), np.array(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "028edb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load the dataset from cache, otherwise load it from the given path and cache it for future use\n",
    "def get_cached_dataset(data_path, force_reload=False):\n",
    "    cache_dir = os.path.join(\".cache/\", data_path)\n",
    "    features_cache = os.path.join(cache_dir, \"features.joblib\")\n",
    "    labels_cache = os.path.join(cache_dir, \"labels.joblib\")\n",
    "\n",
    "    if not force_reload and os.path.exists(features_cache) and os.path.exists(labels_cache):\n",
    "        print(f\"Loading cached dataset from {data_path}...\")\n",
    "        features = joblib.load(features_cache)\n",
    "        labels = joblib.load(labels_cache)\n",
    "        return features, labels\n",
    "        \n",
    "    print(f\"Loading dataset from {data_path}...\")\n",
    "    features, labels = load_dataset(data_path)\n",
    "    \n",
    "    print(f\"Caching loaded dataset to {features_cache} and {labels_cache}...\")\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    joblib.dump(features, features_cache, compress=3)\n",
    "    joblib.dump(labels, labels_cache, compress=3)\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c4d41bc-f447-445e-a8d9-2549a3a34901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached dataset from data/chest_xray/train...\n",
      "Loading cached dataset from data/chest_xray/test...\n",
      "Training features shape: (5216, 8100)\n",
      "Training labels shape: (5216,)\n",
      "Test features shape: (624, 8100)\n",
      "Test labels shape: (624,)\n"
     ]
    }
   ],
   "source": [
    "# Load the training and validation datasets (checking c)\n",
    "train_features, train_labels = get_cached_dataset(\"data/chest_xray/train\")\n",
    "test_features, test_labels = get_cached_dataset(\"data/chest_xray/test\")\n",
    "\n",
    "print(f\"Training features shape: {train_features.shape}\")\n",
    "print(f\"Training labels shape: {train_labels.shape}\")\n",
    "print(f\"Test features shape: {test_features.shape}\")\n",
    "print(f\"Test labels shape: {test_labels.shape}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7366f36",
   "metadata": {},
   "source": [
    "Section 1: randomly picked N elements approach\n",
    "\n",
    "(we decide to label 10% of the unlabled images we have. we pick randomly which ones to label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d01da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: show off how poorly perform a randomly choosen training \n",
    "# like the old one but with less labeled samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b4c07",
   "metadata": {},
   "source": [
    "Section 2: active learning approach with N labeled elements\n",
    "\n",
    "(we decide to label 10% of the unlabled images we have. we pick which ones to label using active learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0042a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: repeat the same stuff above BUT with an active learning \n",
    "# loop to show off much better performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb62bbd7",
   "metadata": {},
   "source": [
    "Section 3: original model (traditional but with all samples)\n",
    "\n",
    "(we decide to label all the unlabled images we have)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442becd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: almost a copy of original steps \n",
    "# to show that the active learning approach achieves similar \n",
    "# results but with less data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45791e12",
   "metadata": {},
   "source": [
    "Section 4: fancy graphs to prove our thesis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
